{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "e081740e-8169-4481-b1df-f5dd5488314f",
    "_uuid": "0bee86255243664f24e4bcf48af2228a3100a8b7"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from trackml.dataset import load_event, load_dataset\n",
    "from trackml.score import score_event\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "def create_one_event_submission(event_id, hits, labels):\n",
    "    sub_data = np.column_stack(([event_id]*len(hits), hits.hit_id.values, labels))\n",
    "    submission = pd.DataFrame(data=sub_data, columns=[\"event_id\", \"hit_id\", \"track_id\"]).astype(int)\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend(submission, hits, limit=0.04, num_neighbours=18, threshold=0.01):\n",
    "\n",
    "    df = submission.merge(hits,  on=['hit_id'], how='left')\n",
    "    df = df.assign(d = np.sqrt( df.x**2 + df.y**2 + df.z**2 ))\n",
    "    df = df.assign(r = np.sqrt( df.x**2 + df.y**2))\n",
    "    df = df.assign(arctan2 = np.arctan2(df.z, df.r))\n",
    "\n",
    "    for angle in range(-90,90,1):\n",
    "\n",
    "        df1 = df.loc[(df.arctan2>(angle-1.5)/180*np.pi) & (df.arctan2<(angle+1.5)/180*np.pi)]\n",
    "\n",
    "        min_num_neighbours = len(df1)\n",
    "        if min_num_neighbours<3: continue\n",
    "\n",
    "        hit_ids = df1.hit_id.values\n",
    "        x,y,z = df1[['x', 'y', 'z']].values.T\n",
    "        r  = (x**2 + y**2)**0.5\n",
    "        r  = r/1000\n",
    "        a  = np.arctan2(y,x)\n",
    "        c = np.cos(a)\n",
    "        s = np.sin(a)\n",
    "\n",
    "        tree = KDTree(np.column_stack([c, s, r]), metric='euclidean')\n",
    "\n",
    "        track_ids = list(df1.track_id.unique())\n",
    "        num_track_ids = len(track_ids)\n",
    "        min_length=3\n",
    "\n",
    "        for i in range(num_track_ids):\n",
    "            p = track_ids[i]\n",
    "            if p==0: continue\n",
    "\n",
    "            idx = np.where(df1.track_id==p)[0]\n",
    "            if len(idx)<min_length: continue\n",
    "\n",
    "            if angle>0:\n",
    "                idx = idx[np.argsort( z[idx])]\n",
    "            else:\n",
    "                idx = idx[np.argsort(-z[idx])]\n",
    "\n",
    "\n",
    "            ## start and end points  ##\n",
    "            idx0,idx1 = idx[0],idx[-1]\n",
    "            a0 = a[idx0]\n",
    "            a1 = a[idx1]\n",
    "            r0 = r[idx0]\n",
    "            r1 = r[idx1]\n",
    "            c0 = c[idx0]\n",
    "            c1 = c[idx1]\n",
    "            s0 = s[idx0]\n",
    "            s1 = s[idx1]\n",
    "\n",
    "            da0 = a[idx[1]] - a[idx[0]]  #direction\n",
    "            dr0 = r[idx[1]] - r[idx[0]]\n",
    "            direction0 = np.arctan2(dr0,da0)\n",
    "\n",
    "            da1 = a[idx[-1]] - a[idx[-2]]\n",
    "            dr1 = r[idx[-1]] - r[idx[-2]]\n",
    "            direction1 = np.arctan2(dr1,da1)\n",
    "\n",
    "            ## extend start point\n",
    "            ns = tree.query([[c0, s0, r0]], k=min(num_neighbours, min_num_neighbours), return_distance=False)\n",
    "            ns = np.concatenate(ns)\n",
    "\n",
    "            direction = np.arctan2(r0 - r[ns], a0 - a[ns])\n",
    "            diff = 1 - np.cos(direction - direction0)\n",
    "            ns = ns[(r0 - r[ns] > threshold) & (diff < (1 - np.cos(limit)))]\n",
    "            for n in ns: df.loc[df.hit_id == hit_ids[n], 'track_id'] = p\n",
    "\n",
    "            ## extend end point\n",
    "            ns = tree.query([[c1, s1, r1]], k=min(num_neighbours, min_num_neighbours), return_distance=False)\n",
    "            ns = np.concatenate(ns)\n",
    "\n",
    "            direction = np.arctan2(r[ns] - r1, a[ns] - a1)\n",
    "            diff = 1 - np.cos(direction - direction1)\n",
    "            ns = ns[(r[ns] - r1 > threshold) & (diff < (1 - np.cos(limit)))]\n",
    "            for n in ns:  df.loc[df.hit_id == hit_ids[n], 'track_id'] = p\n",
    "\n",
    "    df = df[['event_id', 'hit_id', 'track_id']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "572fcbb6-8c7b-4a09-8916-8ec76689130f",
    "_uuid": "63414de98667e95f60407c9155899a25a321cffc"
   },
   "outputs": [],
   "source": [
    "# Change this according to your directory preferred setting\n",
    "path_to_train = \"./train_1\"\n",
    "\n",
    "# This event is in Train_1\n",
    "event_prefix = \"event000001000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_0 = np.array([1.1, 1.1, .375, .25, 0.05, 0.05, 0])\n",
    "weights_2 = np.array([1.05, 1.05, .37, .25, .01, .045, 0])\n",
    "weights_3 = np.array([1.08, 1.08, .38,.25, 0.009, 0.0001, 0])\n",
    "weights_4 = np.array([1.1, 1.1, .5, .25, 0.008, 0.001, 0])\n",
    "weights_5 = np.array([1.01, 1.01, .4048, .2, 2e-16, 2e-16, 0])\n",
    "weights_9 = np.array([1.02, 1.02, .38, .25, 0.009, 0.02, 0])\n",
    "\n",
    "weights_1 = np.array([1.08, 1.08, .38,.25, 0.0001, 0.0001, 0])\n",
    "weights_6 = np.array([1.08, 1.08, .38, .25, 2e-4, 0, 0])\n",
    "weights_8 = np.array([1.07, 1.07, .37, .25, 0.0002, 0.0001, 0])\n",
    "weights_12 = np.array([1.01, 1.01, .42, .25, 0.0023, 0.001, 0])\n",
    "weights_13 = np.array([1.0, 1.0, .40, .20, 0.0023, 0.0001, 0])\n",
    "weights_14 = np.array([1.02, 1.02, .40, .24, 0.0002, 0, 0])\n",
    "weights_7 = np.array([1.08, 1.08, .40, .20, 0.0023, 0, 0])\n",
    "\n",
    "weights_10 = np.array([1.02, 1.02, .42, .24, 0.0002, 0, 0])\n",
    "weights_11 = np.array([1.08, 1.08, .40, .20, 0.0023, 0.0001, 0])\n",
    "weights_15 = np.array([1.01, 1.01, .42, .25, 0.0002, 0, 0])\n",
    "weights_16 = np.array([1.005, 1.005, .40, .25, 0.0002, 0, 0])\n",
    "weights_17 = np.array([1.02, 1.02, .42, .24, 0.02, 0, 0])\n",
    "weights_18 = np.array([1.033, 1.033, .376, .2, 0.0002, 0, 0])\n",
    "weights_19 = np.array([0.9734, 0.9734, .4072, .2217, 0.0, 0.0, 0])\n",
    "weights_20 = np.array([1.0, 1.0, .42, .24, 0.0, 0, 0])\n",
    "weights_21 = np.array([1.02, 1.02, .42, .24, 0.0, 0, 0])\n",
    "weights_22 = np.array([1.05, 1.05, .4, .25, 0.0, 0, 0])\n",
    "weights_23 = np.array([1.05, 1.05, .5, .25, 0.0, 0, 0])\n",
    "weights_24 = np.array([1.05, 1.05, .4, .20, 0.0, 0, 0])\n",
    "weights_26 = np.array([1.2, 1.2, .45, .15, 0.0, 0, 0])\n",
    "weights_27 = np.array([1.2, 1.2, .45, .20, 0.0, 0, 0])\n",
    "weights_28 = np.array([1.2, 1.2, .45, .25, 0.0, 0, 0])\n",
    "weights_29 = np.array([1.09, 1.09, .5, .20, 0.0, 0, 0])\n",
    "weights_25 = np.array([1.09, 1.09, .45, .20, 0.0, 0, 0])\n",
    "weights_30 = np.array([0.9, .9, .35, .15, 0.0, 0.007, 0.007])\n",
    "weights_31 = np.array([1.09, 1.09, .45, .20, 0.0, 0.005, 0.005])\n",
    "weights_34 = np.array([1.09, 1.09, .45, .20, 0.0, 0.01, 0.01])\n",
    "weights_36 = np.array([1.0, 1.0, .35, .2, 0.0, 0.02, 0.02])\n",
    "weights_32 = np.array([0.9, .9, .35, .2, 0.0, 0.01, 0.01])\n",
    "weights_33 = np.array([1.0, 1.0, .35, .2, 0.0, 0.01, 0.01])\n",
    "weights_37 = np.array([0.9, .9, .4, .2, 0.0, 0.015, 0.015]) # raise w4\n",
    "weights_38 = np.array([0.9, .9, .4, .25, 0.0, 0.01, 0.01])  # raise w3\n",
    "weights_39 = np.array([0.9, .9, .45, .2, 0.0, 0.01, 0.01])\n",
    "weights_40 = np.array([0.95, .95, .4, .2, 0.0, 0.01, 0.01])\n",
    "weights_41 = np.array([0.95, .95, .45, .2, 0.0, 0.01, 0.01])  # 38 + 40\n",
    "weights_42 = np.array([0.95, .95, .4, .2, 0.0, 0.008, 0.008]) # w4 lowered\n",
    "weights_43 = np.array([1.0, 1.0, .4, .2, 0.0, 0.01, 0.01])    # w1 raised\n",
    "weights_44 = np.array([0.95, .95, .4, .2, 0.0, 0.012, 0.012]) # w4 raised\n",
    "weights_45 = np.array([1.0, 1.0, .4, .2, 0.0, 0.01, 0.01])  # raise w1 from 35\n",
    "weights_46 = np.array([0.9, .9, .4, .2, 0.0, 0.009, 0.009]) # lower w4\n",
    "weights_47 = np.array([0.85, .85, .4, .2, 0.0, 0.01, 0.01]) # lower w1\n",
    "weights_49 = np.array([0.9, .9, .4, .2, 0.0, 0.007, 0.007]) # still lower w4\n",
    "weights_48 = np.array([0.9, .9, .4, .2, 0.0, 0.008, 0.008]) # lower w4\n",
    "weights_51 = np.array([0.9, .9, .4, .2, 0.0, 0.009, 0.009]) # lower w4\n",
    "weights_50 = np.array([0.9, .9, .4, .2, 0.0, 0.011, 0.011]) # higher w4\n",
    "weights_52 = np.array([0.9, .9, .4, .2, 0.0, 0.012, 0.012]) # higher w4\n",
    "weights_53 = np.array([0.9, .9, .4, .2, 0.0, 0.013, 0.013]) # higher w4\n",
    "weights_54 = np.array([0.9, .9, .4, .2, 0.0, 0.014, 0.014]) # higher w4\n",
    "weights_55 = np.array([0.9, .9, .4, .2, 0.0, 0.015, 0.015]) # higher w4\n",
    "weights_56 = np.array([0.9, .9, .5, .2, 0.0, 0.01, 0.01])     # raise w2\n",
    "weights_60 = np.array([0.7, .7, .5, .13, 0.0, 0.01, 0.01])     # raise w2, lower w1, w3\n",
    "weights_59 = np.array([0.9, .9, .55, .1, 0.0, 0.01, 0.01])     # raise w2, lower w3\n",
    "weights_35 = np.array([0.9, .9, .4, .2, 0.0, 0.01, 0.01])     \n",
    "weights_57 = np.array([0.9, .9, .5, .15, 0.0, 0.01, 0.01]) # second best\n",
    "weights_61 = np.array([0.9, .9, .4, .1, 0.0, 0.01, 0.01])  # lower w3 some more\n",
    "weights_62 = np.array([0.9, .9, .45, .1, 0.0, 0.01, 0.01])  # lower w3 and raise w2\n",
    "weights_63 = np.array([0.9, .9, .5, .1, 0.0, 0.01, 0.01])  # raise w2 some more\n",
    "weights_64 = np.array([0.9, .9, .5, .07, 0.0, 0.01, 0.01])  # raise w2 and lower w3 some more\n",
    "weights_65 = np.array([0.9, .9, .35, .15, 0.0, 0.01, 0.01])   # lower w2 a bit\n",
    "weights_66 = np.array([0.9, .9, .35, .2, 0.0, 0.01, 0.01])   # lower w2 a bit and raise w3\n",
    "weights_67 = np.array([0.95, .95, .3, .2, 0.0, 0.012, 0.012])# weights from r optimization\n",
    "weights_68 = np.array([0.96, .96, .35, .2, 0.0, 0.0085, 0.0085])# weights from r optimization\n",
    "weights_69 = np.array([0.9, .9, .4, .15, 0.0, 0.0085, 0.0085])   # w4 down\n",
    "weights_70 = np.array([1.0, 1.0, .4, .1214, 0.0, 0.008, 0.008])   # w4 down\n",
    "weights_71 = np.array([0.9, 0.9, .5, .15, 0.0, 0.0085, 0.0085])   # w4 down\n",
    "weights_73 = np.array([0.9, .9, .45, .15, 0.0, 0.01, 0.01])   # w2 up a bit\n",
    "weights_74 = np.array([0.9, .9, .35, .2, 0.0, 0.011, 0.011])   # w2 down and w3 up\n",
    "weights_72 = np.array([0.9, .9, .4, .15, 0.0, 0.012, 0.012])   # w4 up a bit\n",
    "weights_75 = np.array([0.9, .9, .4, .15, 0.0, 0.014, 0.014]) \n",
    "weights_76 = np.array([0.9, .9, .4, .20, 0.0, 0.014, 0.014]) \n",
    "weights_77 = np.array([0.85, 0.85, .4, .20, 0.0, 0.012, 0.012]) \n",
    "weights_78 = np.array([0.9, .9, .4, .15, 0.005, 0.01, 0.01]) \n",
    "weights_79 = np.array([0.9, .9, .4, .15, 0.0005, 0.01, 0.01]) \n",
    "weights_80 = np.array([0.9, .9, .4, .15, 0.01, 0.01, 0.01]) \n",
    "weights_82 = np.array([0.96, .96, .45, .126, 0.0, 0.007, 0.007])  \n",
    "weights_84 = np.array([0.96, .96, .45, .15, 0.0, 0.0108, 0.0108])  \n",
    "weights_86 = np.array([0.9, .9, .4, .126, 0.0, 0.0108, 0.0108])  \n",
    "weights_85 = np.array([0.96, .96, .4, .15, 0.0, 0.0108, 0.0108])  \n",
    "weights_87 = np.array([1, 1, .4, .13, 0.0, 0.0108, 0.0108])  \n",
    "weights_88 = np.array([0.96, .96, .4, .13, 0.0, 0.0108, 0.0108])  \n",
    "weights_89 = np.array([0.96, .96, .4, .2, 0.0, 0.005, 0.005])  \n",
    "\n",
    "weights_58 = np.array([0.9, .9, .4, .15, 0.0, 0.01, 0.01])   # best so far\n",
    "weights_81 = np.array([0.96, .96, .45, .126, 0.0, 0.0108, 0.0108])  \n",
    "weights_83 = np.array([0.96, .96, .4, .126, 0.0, 0.0108, 0.0108])  \n",
    "\n",
    "weights_arr = np.vstack([weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, weights_7, \n",
    "                         weights_8, weights_9, weights_10, weights_11, weights_12, weights_13, weights_14,  \n",
    "                         weights_15,  weights_16,  weights_17,  weights_18,  weights_19,  weights_20,  weights_21,\n",
    "                         weights_22,  weights_23,  weights_24,  weights_25,  weights_26,  weights_27,  weights_28,\n",
    "                         weights_29,  weights_30,  weights_31,  weights_32,  weights_33,  weights_34,  weights_35, \n",
    "                         weights_36,  weights_37,  weights_38,  weights_39,  weights_40,  weights_41,  weights_42,\n",
    "                         weights_43,  weights_44,  weights_45,  weights_46,  weights_47,  weights_48,  weights_49,\n",
    "                         weights_50,  weights_51,  weights_52,  weights_53,  weights_54,  weights_55,  weights_56,\n",
    "                         weights_57,  weights_58,  weights_59,  weights_60,  weights_61,  weights_62,  weights_63,\n",
    "                         weights_64,  weights_65,  weights_66,  weights_67,  weights_68,  weights_69,  weights_70, \n",
    "                         weights_71,  weights_72,  weights_73,  weights_74,  weights_75,  weights_76,  weights_77,\n",
    "                         weights_78,  weights_79,  weights_80,  weights_81,  weights_82,  weights_83,  weights_84, \n",
    "                         weights_85,  weights_86,  weights_87,  weights_88,  weights_89])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "e06d1ed7-5091-4d67-abb4-5984b137e2e6",
    "_uuid": "c2f70ae63abffcc09a534bb17fb89df8ffddb722",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import hdbscan\n",
    "from scipy import stats\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "class Clusterer(object):\n",
    "    def __init__(self,rz_scales=[0.65, 0.965, 1.5], eps=0.00285, dz0 = 0, stepdz = 1.5e-7, stepeps = 0.001205, \n",
    "                 num_loops=350, final_cluster=1, weight=83, weight_arr=weights_arr, max_size=16, \n",
    "                 step_z=0.0, size_incr=0.95, min_points=1, max_cluster_size=22, final_cluster_size=2, \n",
    "                 extension_loops=28, ext_threshold=0.01, threshold_delta=1.05):\n",
    "        self.max_cluster_size = max_cluster_size\n",
    "        self.rz_scales=rz_scales\n",
    "        self.epsilon = eps\n",
    "        self.dz0 = dz0\n",
    "        self.stepdz = stepdz\n",
    "        self.stepeps = stepeps / num_loops\n",
    "        self.num_loops = num_loops\n",
    "        self.final_cluster = final_cluster\n",
    "        self.weight_arr = weight_arr\n",
    "        self.weights = weight\n",
    "        self.max_size = max_size\n",
    "        self.step_z = step_z\n",
    "        if size_incr != 0:\n",
    "            self.size_incr = (self.max_cluster_size - max_size) / (num_loops * size_incr)\n",
    "        else:\n",
    "            self.size_incr = 0\n",
    "            \n",
    "        self.min_points = min_points\n",
    "        self.final_cluster_size = final_cluster_size\n",
    "        self.extension_loops = extension_loops\n",
    "        self.ext_threshold=ext_threshold\n",
    "        self.threshold_delta=threshold_delta\n",
    "        \n",
    "    # remove outliers\n",
    "    def _eliminate_outliers(self,labels,M):\n",
    "        norms=np.zeros((len(labels)),np.float32)\n",
    "        indices=np.zeros((len(labels)),np.float32)\n",
    "        for i, cluster in tqdm(enumerate(labels),total=len(labels)):\n",
    "            if cluster == 0:\n",
    "                continue\n",
    "            index = np.argwhere(self.clusters==cluster)\n",
    "            index = np.reshape(index,(index.shape[0]))\n",
    "            indices[i] = len(index)\n",
    "            x = M[index]\n",
    "            norms[i] = self._test_quadric(x)\n",
    "        threshold1 = np.percentile(norms,90)*5\n",
    "        threshold2 = 25\n",
    "        threshold3 = 5\n",
    "        for i, cluster in enumerate(labels):\n",
    "            if norms[i] > threshold1 or indices[i] > threshold2 or indices[i] < threshold3:\n",
    "                self.clusters[self.clusters==cluster]=0   \n",
    "    \n",
    "    # not sure what this function does?\n",
    "    def _test_quadric(self,x):\n",
    "        if x.size == 0 or len(x.shape)<2:\n",
    "            return 0\n",
    "        Z = np.zeros((x.shape[0],10), np.float32)\n",
    "        Z[:,0] = x[:,0]**2\n",
    "        Z[:,1] = 2*x[:,0]*x[:,1]\n",
    "        Z[:,2] = 2*x[:,0]*x[:,2]\n",
    "        Z[:,3] = 2*x[:,0]\n",
    "        Z[:,4] = x[:,1]**2\n",
    "        Z[:,5] = 2*x[:,1]*x[:,2]\n",
    "        Z[:,6] = 2*x[:,1]\n",
    "        Z[:,7] = x[:,2]**2\n",
    "        Z[:,8] = 2*x[:,2]\n",
    "        Z[:,9] = 1\n",
    "        v, s, t = np.linalg.svd(Z,full_matrices=False)        \n",
    "        smallest_index = np.argmin(np.array(s))\n",
    "        T = np.array(t)\n",
    "        T = T[smallest_index,:]        \n",
    "        norm = np.linalg.norm(np.dot(Z,T), ord=2)**2\n",
    "        return norm\n",
    "\n",
    "    # standard scale our data\n",
    "    def _preprocess(self, hits):\n",
    "        # old preprocess, may work better?\n",
    "        x = hits.x.values\n",
    "        y = hits.y.values\n",
    "        z = hits.z.values\n",
    "\n",
    "        r = np.sqrt(x**2 + y**2 + z**2)\n",
    "        hits['x2'] = x/r\n",
    "        hits['y2'] = y/r\n",
    "        hits['xy'] = x/y\n",
    "\n",
    "        r = np.sqrt(x**2 + y**2)\n",
    "        hits['z2'] = z/r\n",
    "\n",
    "        ss = StandardScaler()\n",
    "        X = ss.fit_transform(hits[['x2', 'y2', 'xy', 'z2']].values)\n",
    "        for i, rz_scale in enumerate(self.rz_scales):\n",
    "            X[:,i] = X[:,i] * rz_scale\n",
    "       \n",
    "        return X\n",
    "    \n",
    "    def preprocess_outliers(self, hits):\n",
    "        hits2 = hits.copy()\n",
    "    \n",
    "        x,y,z = hits[['x', 'y', 'z']].values.T\n",
    "        r  = (x**2 + y**2)**0.5\n",
    "        r  = r/1000\n",
    "        a  = np.arctan2(y,x)\n",
    "        c = np.cos(a)\n",
    "        s = np.sin(a)\n",
    "        x2 = x / (r * 1000)\n",
    "        y2 = y / (r * 1000)\n",
    "        z2 = z / (r * 1000)\n",
    "        \n",
    "        hits2['c'] = c\n",
    "        hits2['s'] = s\n",
    "        hits2['r'] = r\n",
    "        hits2['x2'] = x2\n",
    "        hits2['y2'] = y2\n",
    "        hits2['z2'] = z2\n",
    "\n",
    "        return hits2\n",
    "    \n",
    "    def assign_outliers(self, hits):\n",
    "        # add the clusters to our hits\n",
    "        hits['track_id'] = self.clusters\n",
    "        \n",
    "        # get the size of each cluster\n",
    "        hits['N1'] = hits.groupby('track_id')['track_id'].transform('count')\n",
    "        \n",
    "        # if the cluster has size 1 or is 0\n",
    "        outliers_mask = ( (hits['N1'] == 1) | (hits['track_id'] == 0) )\n",
    "        outliers = hits[outliers_mask]\n",
    "        \n",
    "        # mask for even tracks\n",
    "        even_tracks_mask = ((hits['N1'] % 2) == 0)\n",
    "        even_tracks = hits[even_tracks_mask]\n",
    "        \n",
    "        # make sure we have outliers and even tracks to use\n",
    "        if (len(outliers) > 0) and (len(even_tracks) > 0):\n",
    "            print(\"Event:\", self.event_id, \"assigning outliers\")\n",
    "            \n",
    "            # preprocess the even tracks and fit nearest neighbors to it\n",
    "            X = self.preprocess_outliers(even_tracks)\n",
    "            outliers_proc = self.preprocess_outliers(outliers)\n",
    "\n",
    "            nbrs = NearestNeighbors(n_neighbors=1, algorithm='kd_tree').fit(X[['c', 's', 'r']])\n",
    "            indices = nbrs.kneighbors(outliers_proc[['c', 's', 'r']], n_neighbors=1, return_distance=False)\n",
    "            outliers['nbr'] = indices\n",
    "\n",
    "            nbrs = NearestNeighbors(n_neighbors=1, algorithm='kd_tree').fit(X)\n",
    "\n",
    "            # assign the outliers to the track of the nearest neighbor\n",
    "            for index, row in outliers.iterrows():\n",
    "                outliers.loc[index, 'track_id'] = X.iloc[int(row['nbr'])]['track_id']\n",
    "\n",
    "            # merge the outliers back into hits\n",
    "            hits.loc[outliers_mask, 'track_id'] = outliers['track_id']\n",
    "        \n",
    "        self.clusters = hits['track_id']\n",
    "        \n",
    "        return self.clusters\n",
    "\n",
    "    def _init(self,dfh):\n",
    "        dfh['s1'] = dfh.hit_id\n",
    "        dfh['N1'] =1\n",
    "        dfh['stepped_z'] = dfh.z\n",
    "        dfh['e1'] = self.epsilon\n",
    "        dfh['group_locked'] = 0\n",
    "        \n",
    "        mm = 1\n",
    "        dz0 = self.dz0\n",
    "        \n",
    "        cx = self.weight_arr[self.weights]\n",
    "        \n",
    "        for ii in range(self.num_loops):\n",
    "            max_size = np.max([self.max_size + (ii * self.size_incr), self.max_cluster_size])\n",
    "            \n",
    "            dfh['r'] = np.sqrt(dfh['x'].values**2+dfh['y'].values**2+dfh['stepped_z'].values**2)\n",
    "            dfh['rt'] = np.sqrt(dfh['x'].values**2+dfh['y'].values**2)\n",
    "            dfh['a0'] = np.arctan2(dfh['y'].values,dfh['x'].values)\n",
    "            dfh['z1'] = dfh['stepped_z'].values/dfh['rt'].values\n",
    "            \n",
    "            dfh['z2'] = dfh['stepped_z']/dfh['r']\n",
    "            #Samrat\n",
    "            dfh['z4'] = 1/dfh['z1'].values\n",
    "            dfh['x2'] = dfh['x'].values/dfh['r'].values\n",
    "            dfh['y2'] = dfh['y'].values/dfh['r'].values\n",
    "            \n",
    "            #Samrat\n",
    "            dfh['z3'] = 0\n",
    "            mm = mm*(-1)  \n",
    "            \n",
    "            z_step = 0\n",
    "            dz = mm*((ii*self.stepdz))\n",
    "            \n",
    "            dfh['stepped_z'] = dfh['z'] + z_step    \n",
    "            \n",
    "            dfh['a1'] = dfh['a0']+mm*(dfh['rt']+(dz)*dfh['rt']**2)/1000*(ii/2)/180*math.pi\n",
    "            dfh['sina1'] = np.sin(dfh['a1'].values)\n",
    "            dfh['cosa1'] = np.cos(dfh['a1'].values)\n",
    " \n",
    "            #Samrat ->\n",
    "            dfh['x1'] = dfh['a1'].values/dfh['z1'].values\n",
    "            dfh['x_y'] = dfh['x'].values/dfh['y'].values\n",
    "            dfh['x_rt'] = dfh['x'].values/dfh['rt'].values\n",
    "            dfh['y_rt'] = dfh['y'].values/dfh['rt'].values\n",
    "            #Samrat <-\n",
    "\n",
    "            ss = StandardScaler()\n",
    "            dfs = ss.fit_transform(dfh[['sina1','cosa1','z1','z2', 'rt', 'x2', 'y2']].values)\n",
    "            dfs = np.multiply(dfs, cx)\n",
    "\n",
    "            clusters=DBSCAN(eps=self.epsilon+(ii*self.stepeps),min_samples=self.min_points,metric='euclidean',\n",
    "                            n_jobs=4).fit(dfs).labels_ \n",
    "\n",
    "            if ii==0:\n",
    "                dfh['s1'] = clusters\n",
    "                dfh['N1'] = dfh.groupby('s1')['s1'].transform('count')\n",
    "                \n",
    "            # else update our hits conditionally, if it's a better fit\n",
    "            else:\n",
    "                # put our new clusters to another feature\n",
    "                dfh['s2'] = clusters\n",
    "                dfh['e2'] = self.epsilon+(ii*self.stepeps)\n",
    "                \n",
    "                # get the count of those clusters\n",
    "                dfh['N2'] = dfh.groupby('s2')['s2'].transform('count')\n",
    "                maxs1 = dfh['s1'].max()\n",
    "\n",
    "                # if our new clusters are bigger, but less than our max size, use the new ones instead\n",
    "                cond = np.where((dfh['N2'].values > dfh['N1'].values) & (dfh['N2'].values < max_size))\n",
    "                \n",
    "                s1 = dfh['s1'].values\n",
    "                s1[cond] = dfh['s2'].values[cond]+maxs1\n",
    "                \n",
    "                # write the new clusters back to our dataframe\n",
    "                dfh['s1'] = s1\n",
    "                dfh['s1'] = dfh['s1'].astype('int64')\n",
    "                dfh['N1'] = dfh.groupby('s1')['s1'].transform('count')\n",
    "            \n",
    "        # for debugging\n",
    "        # return dfh\n",
    "        \n",
    "        # return our clusters\n",
    "        return dfh['s1'].values    \n",
    "    \n",
    "    def predict(self, hits, event_id):    \n",
    "        original_hits = hits.copy()\n",
    "        self.event_id = event_id\n",
    "        \n",
    "        # init our clusters\n",
    "        self.clusters = self._init(hits) \n",
    "        \n",
    "        # if we have unassigned points assign them with HDBSCAN\n",
    "        mask = self.clusters == 0\n",
    "        if (np.sum(mask) > 0) & (self.final_cluster >= 1):\n",
    "            # preprocess our data\n",
    "            X = self._preprocess(hits) \n",
    "\n",
    "            # create our last clusterer\n",
    "            cl = hdbscan.HDBSCAN(min_samples=1, min_cluster_size=self.final_cluster_size, metric='braycurtis', \n",
    "                                 cluster_selection_method='leaf', algorithm='best', leaf_size=20)\n",
    "\n",
    "            # labels = unique clusters\n",
    "            labels = np.unique(self.clusters)\n",
    "\n",
    "            # remove outliers\n",
    "            self._eliminate_outliers(labels,X)\n",
    "            mask = self.clusters == 0\n",
    "            \n",
    "            n_labels = 0\n",
    "            # assign unassigned points with HDBSCANS\n",
    "            max_len = np.max(self.clusters)\n",
    "            \n",
    "            if np.sum(mask) > 0:\n",
    "                try:\n",
    "                    self.clusters[mask] = cl.fit_predict(X[mask])+max_len\n",
    "                except:\n",
    "                    print(\"Error with HDBSCAN\")\n",
    "                \n",
    "        # if we still have unassigned points assign them to their nearest neighbor\n",
    "        if self.final_cluster >= 2:\n",
    "            self.clusters = self.assign_outliers(hits)\n",
    "            one_submission['track_id'] = self.clusters\n",
    "        \n",
    "        # create a submission\n",
    "        one_submission = create_one_event_submission(event_id, original_hits, self.clusters)\n",
    "        \n",
    "        threshold = self.ext_threshold\n",
    "        \n",
    "        # extend the submission\n",
    "        for i in range(self.extension_loops): \n",
    "            one_submission = extend(one_submission, original_hits, threshold=threshold)\n",
    "            \n",
    "            # decay the threshold\n",
    "            threshold = threshold * self.threshold_delta\n",
    "        \n",
    "        self.clusters = one_submission['track_id']\n",
    "        \n",
    "        return one_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "70612062632493a78bec5bd5c69c5d4d523b8b83"
   },
   "outputs": [],
   "source": [
    "path_to_test = \"./test\"\n",
    "filename = \"dbscan_outliers\"\n",
    "eps = 0.0035\n",
    "dz0 = -0.00070\n",
    "stepdz = 0.00001\n",
    "stepeps = 0.000002\n",
    "\n",
    "def one_loop(event_id):\n",
    "    hits  = pd.read_csv(path_to_test + '/event%s-hits.csv'%event_id)\n",
    "    cells = pd.read_csv(path_to_test + '/event%s-cells.csv'%event_id)\n",
    "    print('Event ID: ', event_id)\n",
    "                \n",
    "    # Track pattern recognition \n",
    "    model = Clusterer()\n",
    "    one_submission = model.predict(hits, event_id)\n",
    "\n",
    "    # Prepare submission for an event\n",
    "#     one_submission = create_one_event_submission(event_id, hits, labels)\n",
    "    \n",
    "#     for i in range(10): \n",
    "#         one_submission = extend(one_submission, hits)\n",
    "            \n",
    "    one_submission.to_csv('./aug_04/%09d.dbscan_outliers_tuned.csv.gz'%int(event_id), index=False, \n",
    "                          compression='gzip')\n",
    "    \n",
    "    return one_submission\n",
    "\n",
    "def create_test_submissions(path_to_test = \"./test\", start=0, end=125):\n",
    "    event_ids = [ '%09d'%i for i in range(start,end) ]\n",
    "\n",
    "    pool = Pool(processes=4)\n",
    "    results = pool.map(one_loop, event_ids)\n",
    "    pool.close()\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000016\n",
      "Event ID:  000000024\n",
      "Event ID:  000000008\n",
      "Event ID:  000000000\n",
      "Event ID:  000000017\n",
      "Event ID:  000000009\n",
      "Event ID:  000000025\n",
      "Event ID:  000000001\n",
      "Event ID:  000000026\n",
      "Event ID:  000000010\n",
      "Event ID:  000000018\n",
      "Event ID:  000000002\n",
      "Event ID:  000000027\n",
      "Event ID:  000000019\n",
      "Event ID:  000000011\n",
      "Event ID:  000000003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e35d862917e94336b1e143224d0e9fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=35644), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99173b769fc4923a0982eec0b18b063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=37735), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000028\n",
      "Event ID:  000000020\n",
      "Event ID:  000000012\n",
      "Event ID:  000000004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddcc0748f6644b298dac7cb3fc3c5bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=41920), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000021\n",
      "Event ID:  000000029\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53b509835d548ba8435ad3df6802316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=37509), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000013\n",
      "Event ID:  000000005\n",
      "Event ID:  000000022\n",
      "Event ID:  000000030\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39ca3f9f8a94ad6b07d3e083ea0a030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39197), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000014\n",
      "Event ID:  000000006\n",
      "Event ID:  000000031\n",
      "Event ID:  000000023\n",
      "Event ID:  000000015\n",
      "Event ID:  000000007\n",
      "Event ID:  000000032\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50496a7813274e3c986f36c9e5bff997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=30732), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000040\n",
      "Event ID:  000000048\n",
      "Event ID:  000000033\n",
      "Event ID:  000000056\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8adff374cb4d7399f8f152278253a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39976), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000041\n",
      "Event ID:  000000049\n",
      "Event ID:  000000034\n",
      "Event ID:  000000057\n",
      "Event ID:  000000042\n",
      "Event ID:  000000050\n",
      "Event ID:  000000035\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbcebce30c04223bc45bfd1313fed34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=38627), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000058\n",
      "Event ID:  000000043\n",
      "Event ID:  000000036\n",
      "Event ID:  000000051\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dd80d0c05b94e2fa65495385435de87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=39321), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000059\n",
      "Event ID:  000000044\n",
      "Event ID:  000000037\n",
      "Event ID:  000000052\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67b96305c2e4ebca44de9e03c199f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47643), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000060\n",
      "Event ID:  000000045\n",
      "Event ID:  000000053\n",
      "Event ID:  000000038\n",
      "Event ID:  000000061\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54d0067ba3154e8aaf7ce1d20dce65f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=38322), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f122f1292a264c85b70dd36293b0b9e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=37309), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000046\n",
      "Event ID:  000000054\n",
      "Event ID:  000000039\n",
      "Event ID:  000000062\n",
      "Event ID:  000000047\n",
      "Event ID:  000000055\n",
      "Event ID:  000000064\n",
      "Event ID:  000000063\n",
      "Event ID:  000000072\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939f1e0a77b7480d812a8b63ebe19e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=37540), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000080\n",
      "Event ID:  000000065\n",
      "Event ID:  000000073\n",
      "Event ID:  000000088\n",
      "Event ID:  000000066\n",
      "Event ID:  000000081\n",
      "Event ID:  000000074\n",
      "Event ID:  000000089\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017b7dd82d99480cb32cc2ecea2a314f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40420), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000067\n",
      "Event ID:  000000082\n",
      "Event ID:  000000075\n",
      "Event ID:  000000090\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef0346b9d6f46f1987b88e4e4347886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=35334), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000083\n",
      "Event ID:  000000076\n",
      "Event ID:  000000068\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20680978a7b435a9651098ad67f72eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36684), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000091\n",
      "Event ID:  000000077\n",
      "Event ID:  000000069\n",
      "Event ID:  000000084\n",
      "Event ID:  000000092\n",
      "Event ID:  000000078\n",
      "Event ID:  000000085\n",
      "Event ID:  000000070\n",
      "Event ID:  000000093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b7d91915044ef881f6a4a9b1ce5a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=36200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97502714c9364745a96dc2bf626ccb8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=45951), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000079\n",
      "Event ID:  000000071\n",
      "Event ID:  000000086\n",
      "Event ID:  000000094\n",
      "Event ID:  000000096\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b73493fc694e6cbcf1d31eecb24222",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=34835), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000104\n",
      "Event ID:  000000087\n",
      "Event ID:  000000095\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2859ce63a854ac2bbfee9cfda34e507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=41151), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000097\n",
      "Event ID:  000000105\n",
      "Event ID:  000000112\n",
      "Event ID:  000000120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9254a4607503457a88a773203258fc57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=38339), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000098\n",
      "Event ID:  000000106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcffeaec2b34465087a97bf005668b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=40562), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000113\n",
      "Event ID:  000000121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed1de16717347d196d83d34fc24328c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=44039), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000099\n",
      "Event ID:  000000107\n",
      "Event ID:  000000114\n",
      "Event ID:  000000122\n",
      "Event ID:  000000100\n",
      "Event ID:  000000108\n",
      "Event ID:  000000115\n",
      "Event ID:  000000123\n",
      "Event ID:  000000101\n",
      "Event ID:  000000116\n",
      "Event ID:  000000109\n",
      "Event ID:  000000124\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365ac60318714de999c5efd8249023b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=38269), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samrat/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py:547: UserWarning: Multiprocessing-backed parallel loops cannot be nested, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event ID:  000000102\n",
      "Event ID:  000000117\n",
      "Event ID:  000000110\n",
      "Event ID:  000000103\n",
      "Event ID:  000000111\n",
      "Event ID:  000000118\n",
      "Event ID:  000000119\n"
     ]
    }
   ],
   "source": [
    "_ = create_test_submissions(start=0, end=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13741466\n"
     ]
    }
   ],
   "source": [
    "event_ids = [ i for i in range(0,125) ]\n",
    "submissions = []\n",
    "for i,event_id in enumerate(event_ids):\n",
    "    submission  = pd.read_csv('./aug_04/%09d.dbscan_outliers_tuned_2.csv.gz'%event_id, compression='gzip')\n",
    "    submissions.append(submission)\n",
    "\n",
    "# Create submission file\n",
    "submission = pd.concat(submissions, axis=0)\n",
    "submission.to_csv('dbscan_opt_w_ext_aug_04.csv.gz', index=False, compression='gzip')\n",
    "print(len(submission))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
